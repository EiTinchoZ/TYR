{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# REENTRENAMIENTO TYR - GUARDAR PESOS Y MODELO COMPLETO\n",
    "\n",
    "Este notebook entrena el modelo y guarda tanto los pesos (.pth) como el modelo completo (.safetensors).\n",
    "\n",
    "**IMPORTANTE**: Verifica que el modelo funcione ANTES de guardarlo (PASO 12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 1: Instalar dependencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install transformers torch datasets scikit-learn -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 2: Importar librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import torch\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForSequenceClassification,\n",
    "    Trainer, \n",
    "    TrainingArguments\n",
    ")\n",
    "from datasets import Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score\n",
    "import numpy as np\n",
    "\n",
    "print(\"Librerías importadas correctamente\")\n",
    "print(f\"Torch version: {torch.__version__}\")\n",
    "print(f\"CUDA disponible: {torch.cuda.is_available()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 3: Cargar Dataset\n",
    "\n",
    "**INSTRUCCIONES:**\n",
    "1. Sube el archivo `Dataset_TYR_3000_FINAL.json` a Colab\n",
    "2. Ejecuta esta celda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar dataset\n",
    "with open('Dataset_TYR_3000_FINAL.json', 'r', encoding='utf-8') as f:\n",
    "    data_raw = json.load(f)\n",
    "\n",
    "print(f\"Dataset cargado: {len(data_raw)} ejemplos\")\n",
    "\n",
    "# Contar por intención\n",
    "intenciones_count = {}\n",
    "for texto, intencion in data_raw:\n",
    "    intenciones_count[intencion] = intenciones_count.get(intencion, 0) + 1\n",
    "\n",
    "print(\"\\nDistribución por intención:\")\n",
    "for intencion, count in sorted(intenciones_count.items()):\n",
    "    print(f\"  {intencion}: {count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 4: Crear label_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Label map\n",
    "label_map = {\n",
    "    \"becas_financiamiento\": 0,\n",
    "    \"contacto_ubicacion\": 1,\n",
    "    \"faq_general\": 2,\n",
    "    \"fuera_dominio\": 3,\n",
    "    \"horarios_duracion\": 4,\n",
    "    \"informacion_carreras\": 5,\n",
    "    \"informacion_institucional\": 6,  # NUEVA CLASE\n",
    "    \"inscripcion_admision\": 7,\n",
    "    \"requisitos_ingreso\": 8,\n",
    "    \"saludo_despedida\": 9\n",
    "}\n",
    "\n",
    "id2label = {v: k for k, v in label_map.items()}\n",
    "\n",
    "print(f\"Label map creado: {len(label_map)} clases\")\n",
    "print(\"\\nClases:\")\n",
    "for idx, label in sorted(id2label.items()):\n",
    "    print(f\"  {idx}: {label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 5: Preparar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir a formato con IDs numéricos\n",
    "textos = [item[0] for item in data_raw]\n",
    "labels = [label_map[item[1]] for item in data_raw]\n",
    "\n",
    "# Split train/test\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    textos, labels, test_size=0.2, random_state=42, stratify=labels\n",
    ")\n",
    "\n",
    "print(f\"Train: {len(X_train)} ejemplos\")\n",
    "print(f\"Test: {len(X_test)} ejemplos\")\n",
    "\n",
    "# Verificar que informacion_institucional está presente\n",
    "info_inst_train = sum(1 for label in y_train if label == 6)\n",
    "info_inst_test = sum(1 for label in y_test if label == 6)\n",
    "print(f\"\\nEjemplos de 'informacion_institucional' (clase 6):\")\n",
    "print(f\"  Train: {info_inst_train}\")\n",
    "print(f\"  Test: {info_inst_test}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 6: Cargar tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = \"dccuchile/bert-base-spanish-wwm-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "print(f\"Tokenizer cargado: {model_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 7: Tokenizar datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear datasets\n",
    "train_dataset = Dataset.from_dict({\"text\": X_train, \"label\": y_train})\n",
    "test_dataset = Dataset.from_dict({\"text\": X_test, \"label\": y_test})\n",
    "\n",
    "# Tokenizar\n",
    "def tokenize_function(examples):\n",
    "    return tokenizer(examples[\"text\"], padding=\"max_length\", truncation=True, max_length=128)\n",
    "\n",
    "train_dataset = train_dataset.map(tokenize_function, batched=True)\n",
    "test_dataset = test_dataset.map(tokenize_function, batched=True)\n",
    "\n",
    "print(\"Datos tokenizados\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 8: Cargar modelo BERT base"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo base con 10 clases\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    model_name,\n",
    "    num_labels=len(label_map),\n",
    "    id2label=id2label,\n",
    "    label2id=label_map,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "\n",
    "print(f\"Modelo cargado con {len(label_map)} clases\")\n",
    "print(f\"Classifier output size: {model.classifier.out_features}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 9: Configurar entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Métricas\n",
    "def compute_metrics(pred):\n",
    "    labels = pred.label_ids\n",
    "    preds = pred.predictions.argmax(-1)\n",
    "    acc = accuracy_score(labels, preds)\n",
    "    f1 = f1_score(labels, preds, average='weighted')\n",
    "    return {'accuracy': acc, 'f1': f1}\n",
    "\n",
    "# Training arguments - NO GUARDAR CHECKPOINTS\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results_temp\",\n",
    "    num_train_epochs=3,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=32,\n",
    "    learning_rate=2e-5,\n",
    "    weight_decay=0.01,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"no\",  # NO GUARDAR NADA durante el training\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=100,\n",
    "    fp16=torch.cuda.is_available(),\n",
    "    warmup_steps=500,\n",
    "    report_to=\"none\"\n",
    ")\n",
    "\n",
    "# Trainer SIN EarlyStoppingCallback\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=test_dataset,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "print(\"Trainer configurado (sin early stopping)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 10: ENTRENAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Iniciando entrenamiento...\\n\")\n",
    "trainer.train()\n",
    "print(\"\\nEntrenamiento completado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 11: Evaluar en test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar\n",
    "results = trainer.evaluate()\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RESULTADOS EN TEST SET\")\n",
    "print(\"=\" * 60)\n",
    "print(f\"Accuracy: {results['eval_accuracy']:.4f} ({results['eval_accuracy']*100:.2f}%)\")\n",
    "print(f\"F1-Score: {results['eval_f1']:.4f} ({results['eval_f1']*100:.2f}%)\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 12: PROBAR MODELO EN MEMORIA (ANTES DE GUARDAR)\n",
    "\n",
    "**CRÍTICO**: Probar el modelo ANTES de guardarlo para verificar que funciona correctamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preguntas de prueba sobre información institucional\n",
    "test_questions = [\n",
    "    \"Cuándo se fundó el ITSE?\",\n",
    "    \"Qué reconocimientos tiene el ITSE?\",\n",
    "    \"El MIT colabora con el ITSE?\",\n",
    "    \"Cuál es la empleabilidad del ITSE?\",\n",
    "    \"Qué es el CAIPI?\",\n",
    "    \"Quién es la rectora del ITSE?\"\n",
    "]\n",
    "\n",
    "# Poner modelo en modo evaluación\n",
    "model.eval()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PRUEBA DE PREGUNTAS INSTITUCIONALES (MODELO EN MEMORIA)\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correctas = 0\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    # Tokenizar\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    # Predecir\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        pred_class = outputs.logits.argmax(-1).item()\n",
    "        confidence = probs[0][pred_class].item()\n",
    "    \n",
    "    pred_label = id2label[pred_class]\n",
    "    is_correct = pred_label == \"informacion_institucional\"\n",
    "    if is_correct:\n",
    "        correctas += 1\n",
    "    \n",
    "    status = \"✅\" if is_correct else \"❌\"\n",
    "    print(f\"{i}. {status} \\\"{question}\\\"\")\n",
    "    print(f\"   → {pred_label} ({confidence*100:.2f}%)\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"RESULTADO: {correctas}/6 correctas\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if correctas >= 5:\n",
    "    print(\"\\n✅ MODELO FUNCIONA CORRECTAMENTE - Continuar con guardado\")\n",
    "else:\n",
    "    print(\"\\n⚠️ ADVERTENCIA: El modelo no clasifica correctamente\")\n",
    "    print(\"NO continuar con el guardado\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 13: GUARDAR PESOS (.pth)\n",
    "\n",
    "**IMPORTANTE**: Solo ejecutar si el PASO 12 muestra 5/6 o 6/6 correctas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardar SOLO los pesos del modelo\n",
    "torch.save(model.state_dict(), 'modelo_tyr_10_clases_PESOS.pth')\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"PESOS GUARDADOS EN: modelo_tyr_10_clases_PESOS.pth\")\n",
    "print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 14: GUARDAR MODELO COMPLETO (.safetensors)\n",
    "\n",
    "Guardamos también el modelo completo para tener ambos formatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Crear carpeta para el modelo completo\n",
    "modelo_dir = \"modelo_bert_tyr_10_clases_COMPLETO\"\n",
    "os.makedirs(modelo_dir, exist_ok=True)\n",
    "\n",
    "# Guardar modelo completo\n",
    "model.save_pretrained(modelo_dir)\n",
    "tokenizer.save_pretrained(modelo_dir)\n",
    "\n",
    "# Guardar label_map\n",
    "label_map_save = {str(k): v for k, v in id2label.items()}\n",
    "with open(f'{modelo_dir}/label_map.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(label_map_save, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"MODELO COMPLETO GUARDADO EN: {modelo_dir}/\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nArchivos guardados:\")\n",
    "print(\"  - config.json\")\n",
    "print(\"  - model.safetensors\")\n",
    "print(\"  - tokenizer_config.json\")\n",
    "print(\"  - vocab.txt\")\n",
    "print(\"  - label_map.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 15: VERIFICAR modelo completo guardado\n",
    "\n",
    "Cargar el modelo desde la carpeta y verificar que funciona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar modelo desde carpeta\n",
    "model_verificacion = AutoModelForSequenceClassification.from_pretrained(modelo_dir)\n",
    "model_verificacion.eval()\n",
    "model_verificacion.to(device)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"VERIFICACIÓN: MODELO COMPLETO DESDE CARPETA\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "correctas_completo = 0\n",
    "for i, question in enumerate(test_questions, 1):\n",
    "    inputs = tokenizer(question, return_tensors=\"pt\", padding=True, truncation=True, max_length=128)\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        outputs = model_verificacion(**inputs)\n",
    "        probs = torch.nn.functional.softmax(outputs.logits, dim=-1)\n",
    "        pred_class = outputs.logits.argmax(-1).item()\n",
    "        confidence = probs[0][pred_class].item()\n",
    "    \n",
    "    pred_label = id2label[pred_class]\n",
    "    is_correct = pred_label == \"informacion_institucional\"\n",
    "    if is_correct:\n",
    "        correctas_completo += 1\n",
    "    \n",
    "    status = \"✅\" if is_correct else \"❌\"\n",
    "    print(f\"{i}. {status} \\\"{question}\\\"\")\n",
    "    print(f\"   → {pred_label} ({confidence*100:.2f}%)\\n\")\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(f\"RESULTADO: {correctas_completo}/6 correctas\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "if correctas_completo >= 5:\n",
    "    print(\"\\n✅ VERIFICACIÓN EXITOSA - Modelo completo funciona\")\n",
    "else:\n",
    "    print(\"\\n❌ ERROR: El modelo completo NO funciona correctamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 16: Comprimir modelo completo\n",
    "\n",
    "Crear un ZIP del modelo completo para descarga más fácil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "\n",
    "# Crear ZIP\n",
    "zip_filename = \"modelo_bert_tyr_10_clases_COMPLETO\"\n",
    "shutil.make_archive(zip_filename, 'zip', modelo_dir)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(f\"ZIP CREADO: {zip_filename}.zip\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "# Mostrar tamaño del archivo\n",
    "import os\n",
    "size_mb = os.path.getsize(f\"{zip_filename}.zip\") / (1024 * 1024)\n",
    "print(f\"\\nTamaño: {size_mb:.2f} MB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PASO 17: RESUMEN FINAL\n",
    "\n",
    "Lista de archivos para descargar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"ARCHIVOS LISTOS PARA DESCARGAR\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\n1. modelo_tyr_10_clases_PESOS.pth (~420 MB)\")\n",
    "print(\"   - Solo pesos del modelo\")\n",
    "print(\"   - Usar con script cargar_pesos_nuevo_modelo.py\")\n",
    "print(\"\\n2. modelo_bert_tyr_10_clases_COMPLETO.zip (~400-500 MB)\")\n",
    "print(\"   - Modelo completo con safetensors\")\n",
    "print(\"   - Listo para usar directamente\")\n",
    "print(\"   - Incluye: model.safetensors, config.json, tokenizer, label_map.json\")\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"RECOMENDACIÓN: Descarga AMBOS archivos\")\n",
    "print(\"=\" * 60)\n",
    "print(\"\\nVerificaciones realizadas:\")\n",
    "print(f\"  - Modelo en memoria: {correctas}/6 correctas ✅\" if correctas >= 5 else f\"  - Modelo en memoria: {correctas}/6 correctas ❌\")\n",
    "print(f\"  - Modelo completo guardado: {correctas_completo}/6 correctas ✅\" if correctas_completo >= 5 else f\"  - Modelo completo guardado: {correctas_completo}/6 correctas ❌\")\n",
    "print(\"\\n✅ TODO LISTO PARA DESCARGAR\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
